---
title: "The Effectiveness of Digital Advertisement in Driving Customer Retention: A Quantitative Analysis of Digital Efficacy"
format: 
  html:
    embed-resources: true
    toc: true
    toc-location: left
    toc-depth: 4
editor: visual
author: Huan Shuo Hsu, Jinyi Liu
---

# **Research Proposal**

## Memo to Decision Makers

#### Purpose / Objective

This document presents a plan to improve Coca-Cola’s advertising strategy for an experimented flavor (New Flavor A) using targeted YouTube campaigns. The main goal is to boost Amazon sales, increase customer subscriptions, and encourage more frequent purchases by understanding how different ad strategies—such as frequency, type, and length—impact consumer behavior.

#### Background and Problem

Coca-Cola has always been at the forefront of innovation, but today’s digital marketplace is more competitive than ever. YouTube ads hold great potential for connecting with consumers, yet it’s not entirely clear how specific factors like how often ads are shown, the type of ads used, or their length influence customer decisions. Without this clarity, there’s a risk of overspending on strategies that don’t deliver results. Research shows that refining these elements could lead to noticeable improvements in sales and loyalty, but to do this effectively, Coca-Cola needs evidence-based insights. The research will use data collected over three months through automated systems that track ad performance, sales, and customer behavior. Using proven statistical methods, the study will identify which strategies work best and provide actionable recommendations.

#### Call to Action

This is an opportunity for Coca-Cola to uncover the most effective ways to reach and engage its audience. By supporting this study, Coca-Cola can make smarter decisions about where to invest its advertising budget and ensure that every dollar spent generates maximum return. We recommend moving forward by finalizing the collaboration, providing access to performance data, and allocating a small budget for data tracking and analysis. Together, we can unlock new insights to strengthen Coca-Cola’s digital marketing strategy and deliver lasting results in a fast-moving market.

## Statement of the Problem

Coca-Cola, a global leader in the beverage industry, is facing increasing competition as consumer preferences shift toward water, seltzer, and other flavored drinks (BrandVM). Coca-Cola's annual revenue for 2022 was `$43.004` billion, a `11.25%` increase from 2021, and in 2023, the company's revenue was `$45.754` billion, an `6.39%` increase from 2022 (DemandSage). These figures demonstrate Coca-Cola's ability to grow its overall business despite changing consumer preferences. The company continues to innovate and adapt its product portfolio, offering a staggering `3,500` varieties across more than `200` countries (BrandVM). To add, this adaptability is especially critical in the increasingly competitive digital marketplace, where organizations must continuously optimize their marketing strategies to effectively engage customers and foster long-term loyalty. For a global brand like Coca-Cola, navigating digital platforms effectively is both an opportunity and a challenge. YouTube, with over two billion monthly logged-in users (Macrotrends), provides a unique avenue for increasing brand awareness, promoting products, and fostering customer loyalty. Recognizing this, Coca-Cola aims to leverage YouTube advertising to boost online sales and engagement for its new products. However, uncertainties persist regarding the effects of ad frequency, format, and length on customer behavior. Without addressing these uncertainties, Coca-Cola may fail to fully capitalize on the potential of YouTube advertising, missing out on opportunities to attract consumers' attention to its innovative products.

The aim of this project is to answer the research questions that were designed to support the research problem.

-   How would increasing the frequency of YouTube ads (from 1 ad per week to 3 ads per week) impact the online sales on Amazon of New Flavour A Coca Cola over the period of three months?

-   Does the type of YouTube ads (skippable ads, non-skippable ads) have a significant impact on the proportion of automatic subscriptions of New Flavor A Coca Cola on Amazon within three months?

-   Is there a significant association between the length (10s and 30s) of the Youtube Ads and the weekly online purchase frequency per customer on Amazon within three months?

## Literature Review

Jordan Valinsky (2024) reported that Coca-Cola faces increasing competition as consumers shift towards water, seltzers, and bold-flavored drinks from smaller brands like Olipop and Poppi. To address this, the company has introduced a new flavor to align with changing consumer tastes driven by demographic shifts and the growing popularity of flavored sodas, which have outpaced traditional cola sales. However, Coca-Cola’s modest 1% sales growth in North America in 2022 underscores the challenge of staying competitive in a dynamic beverage market.

Nowadays, consumers of all ages and demographics are spending a significant amount of their time on the Internet. Due to these trends, businesses have expanded their marketing campaigns to reach consumers through digital platforms. According to Nielsen (2012), an effective advertising campaign attracts a large audience. In 2014, `88%` of businesses invested in social media advertising, which accounted for 5% of their advertising budgets. By 2018, this share was projected to double. Pikas and Sorrentino (2014) explored the efficacy of online advertisements on social media platforms such as Facebook, Twitter and YouTube.

According to Soukup (2014), YouTube has become a crucial platform for business. Scholars and experts highlight its potential for video marketing, effective advertising and brand management. Chadha (2018) noted that nearly `80%` of marketers recognized YouTube as an essential platform for marketing through online digital videos. As a result, YouTube Marketing Communication has become a key promotional strategy, accounting for a significant `25%` share of promotional money. Jarboe (2009) and Miles (2013) emphasized strategies such as campaign planning, video creation and leverage YouTube’s social networking aspects for marketing success. Moon, Jung, and Lee (2011) explored the impact of video quality and format on ad effectiveness. Pashkevich, Dorai-Raj, Kellar, and Zigmond (2012) studied in-stream advertising and skippable ads and further emphasized YouTube’s versatility as a marketing tool. Li and Lo (2014) examined the effects of ad length, location and context congruity. According to the study, ad duration has an impact on brand identification with long ads being more remembered. Firat’s (2019) study examined the factors influencing YouTube advertising value and its impact on consumer purchase intentions. The research identified that attributes such as informativeness, entertainment, and trendiness significantly enhance advertising value. Additionally, the study established a positive correlation between YouTube ads and consumers’ purchase intentions.

To evaluate the effectiveness and advantages of YouTube ads, it is essential to understand how advertising works on the platform. Based on Bauer (2013), YouTube introduced ads in 2006, providing businesses an opportunity to connect with a border audience. The launch featured Participatory Ads and Brand Channels, with more development followed in subsequent years. The platform now offers a wide range of standard ad formats for use in its video streaming services (Google Ads Help)

-   Skippable Ads: These are a common ad format on YouTube. These ads are presented before the selected video will stream and can range from `10` seconds to `6` minutes in length, with viewers having the option to skip the ad after `5` seconds. They may also include a call to action button which is displayed either throughout the ad or after a specified duration. Since viewers can skip this type of ad, the primary goal is to capture and retain their interest. Skippable ads allow advertisers to gather a wide range of data including metrics like completed views, partial views, channel subscriptions and call to action completions.

-   Non-skippable Ads: This form of ads are non-skippable and can be presented before, during or after the selected video. These ads typically last `10` to `30` seconds and are only available for videos longer than `10` minutes. Like skippable ads, non-skippable ads also provide advertisers with valuable performance data.

-   Bumper Ads: These are YouTube’s shortest ad format, lasting up to `6` seconds and appearing at the beginning of a video. Similar to non-skippable ads, they cannot be skipped.

-   Overlay Ads: Also known as banner ads, are displayed within the selected video, hovering at the bottom of the screen. They can appear and disappear at any point during the video.

Subscription e-commerce is a rapidly growing model that offers consumers convenient, personalized, and cost-effective ways to purchase recurring products or services. Amazon’s Subscribe & Save, one of the most popular replenishment subscription services, exemplifies this trend by automating the purchase of essential goods like consumer packaged items at discounted prices with additional perks for subscribers. This approach not only simplifies shopping but also fosters customer loyalty, with `45%` of replenishment subscribers maintaining their membership for over a year. However, subscription businesses face challenges like high churn rates, requiring a focus on delivering superior customer experiences to retain users and ensure sustainable growth. (Chen, Fenyo, Yang, and Zhang, 2018)

Amazon’s Subscribe & Save offers a flexible and cost-effective way to purchase products like Coca Cola. Customers can choose a one-time purchase or opt for the subscription function to save `5%` on each order. This method allows customers to customize their delivery schedule, with intervals ranging from `2` weeks to `6` months, ensuring consistent supply while avoiding the hassle of reordering. This mechanism not only provides convenience but also encourages customer loyalty through savings and tailored delivery options.

## Research Questions, Hypotheses, and Effects

To assess the impact of YouTube advertising on the online performance of New Flavor A Coca-Cola, the experiment will test three key advertising strategies: ad frequency, ad type, and ad length. Targeted YouTube campaigns will be implemented to examine their influence on Amazon sales and subscription metrics over three months. The primary outcomes include changes in Amazon sales revenue, the proportion of automatic subscriptions, and weekly purchase frequency per customer, all measured through specific performance metrics.

### Research Question 1

How would increasing the frequency of YouTube ads (from `1` ad per week to `3` ads per week) impact the online sales on Amazon of New Flavour A Coca Cola (12 Pack) over the period of three months?

-   **Null Hypothesis (H₀)**: Increasing ad frequency does not significantly increase the sales within three months.
-   **Alternative Hypothesis (H₁**): Increasing ad frequency does significantly increase the sales within three months.
-   **Effect size**: A `10%` increase in sales within three months would represent a meaningful improvement.
-   **Outcome and Metric**: Track total online sales on Amazon of New Flavor A Coca Cola, measured in revenue over three months.

### Research Question 2

Does the type of YouTube ads (skippable ads, non-skippable ads) have a significant impact on the proportion of automatic subscriptions of New Flavor A Coca Cola (12 Pack) on Amazon within three months?

-   **Null Hypothesis (H₀)**: The type of YouTube ads does not have a significant impact on the proportion of automatic subscriptions for New Flavor A Coca Cola on Amazon within three months.
-   **Alternative Hypothesis (H₁**):The type of YouTube ads has a significant impact on the proportion of automatic subscriptions for New Flavor A Coca Cola on Amazon within three months.
-   **Effect size**:A `5%` increase in automatic subscriptions would be a meaningful improvement for Coca-Cola.
-   **Outcome and Metric**: Monitor the proportion of subscriptions on Amazon attributed to skippable and non-skippable YouTube ads over three months.

### Research Question 3

Is there a significant association between the length (`10s` and `30s`) of the Youtube Ads and the weekly online purchase frequency of New Flavor A Coca Cola (12 Pack) per customer on Amazon within three months?

-   **Null Hypothesis (H₀)**:There is no significant association between the length of Youtube Ads and the weekly online purchase frequency per customer on Amazon within three months.
-   **Alternative Hypothesis (H₁**): There is a significant association between the length of Youtube ads and the weekly online purchase frequency per customer on Amazon within three months.
-   **Effect size**: A `2` bottle increase in purchase frequency per customer within three months would represent a meaningful`10%` improvement.
-   **Outcome and Metric**: Record the average weekly purchase frequency per customer.

## Importance of the Study and Social Impact

The study is essential for Coca Cola as it explores the dynamic digital marketing environment to effectively promote its new product, New Flavor A Coca Cola. Coca-Cola can maximize its marketing expenditures and deepen consumer brand loyalty by determining the most efficient ad forms, frequencies, and budget allocations. This ensures efficient allocation of advertising budgets while reducing unnecessary spending. Understanding how specific YouTube ads characteristics influence consumer behavior will enable Coca Cola to design campaigns that boost both sales and long-term customer loyalty. As Coca Cola faces competition from sparkling water, seltzers and other beverage categories, innovative marketing techniques are important to retain existing customers and attract new ones in the competitive digital marketplace. Beyond commercial objectives, this study has wider societal ramifications. With companies like Coca-Cola continuing to make significant investments in digital marketing, knowing how to properly engage customers can have an impact on their media consumption habits and behavior. In addition to promoting brand loyalty, effective marketing techniques will result in sustained long term customer satisfaction. Moreover, Coca Cola’s success in innovating healthier or more appealing products could influence broader trends toward mode consumer-conscious offerings in the beverage industry.

## Research Plan

#### Population of Interest

The recruitment process for the study will begin with collecting qualified candidates from Amazon analytics tools across various platforms, including email lists, social media, and targeted advertisements. The recruitment process will not rely on a traditional survey but instead use YouTube’s ad targeting tools to ensure participants meet the inclusion criteria naturally. Using online activity data and purchase behavior from Amazon, the study can focus on consumers who organically interacted with the ads. This approach eliminates the need for direct survey distribution, reducing recruitment bias. The population of interest will consist of consumers aged `18` to `65` who have shopped online after watching YouTube ads relevant to New Flavor A Coca-Cola during the 3-month study period. For the inclusion group, customers with exposure to YouTube ads during the study, having watched at least one relevant ad, made at least one online purchase on Amazon during the study duration, and agreed to participate in the study. For the exclusion group, customers who shopped more than three times a week, or residing outside the geographic area where the YouTube ads are implemented, use ad-blocking software that may prevent them from viewing YouTube ads, have unreliable internet access, which could prevent consistent exposure to YouTube ads, are affiliated with Coca-Cola or its advertising partners, to prevent biases, or have participated in similar studies or experiments involving Coca-Cola or comparable products in the past year.

#### Sample Selection

Participants will be randomly assigned into groups. Group assignment will be independent of participants’ demographic characteristics or previous engagement behavior. Grouping will be automated based on ad engagement data collected by YouTube’s analytics platform. Participants will remain unaware of their assigned groups to prevent bias and ensure natural behavior during the study. Participants will be assigned into groups based on the variables of interest:

-   **Ad Frequency groups**: `700` Participants will be divided into two groups. A control group consisting of `350` individuals exposed to 1 ad per week and an experimental group consisting of `530` individuals exposed to 3 ads per week. (Accounting for dropouts)
-   **Ad Type groups**: `1300` Participants will be divided into two groups. A control group consisting of `650` individuals exposed primarily to skippable ads and an experimental group consisting of `650` individuals exposed to non-skippable ads. (Accounting for dropouts)
-   **Ad Length groups**: `1100` Participants will be divided into two groups. A control group consisting of `550` individuals exposed to 10-second ads and an experimental group consisting of `550` individuals exposed to 30-second ads. (Accounting for dropouts)

#### Operational Procedures

The recruitment process will be conducted through digital platforms such as YouTube and Amazon. Participants will be identified based on their interaction with ads for Coca-Cola’s New Flavor A that only sells on Amazon during the study period, as tracked by YouTube analytics tools. Eligible participants will be invited to participate via online messages including a general overview of the study and an informed consent form. No surveys will be used for recruitment. The study will be conducted online using YouTube’s ad delivery and analytics tools. Once eligibility is confirmed, participants will be randomly assigned to one of two groups, anonymized, and encrypted to avoid selection bias. Participants will be exposed to these ads during their regular online activities. YouTube’s system will ensure that participants are exposed to their designated ad types and engagement data will be automatically collected. Online purchase behavior and subscription data will be tracked through Amazon’s analytics tools. Study personnel will receive training on securely handling data and interpreting data from YouTube and Amazon analytics tools. They will also be trained on ethical considerations, including participant confidentiality and compliance with data protection regulations. Study personnel will inform the participants of instructions during the study period with minimal interaction to avoid influencing behavior, limiting communication to providing initial instructions on how the researcher will track their purchases, periodic reminder of the instruction twice a month, and a follow-up instruction once the research has ended. On top of that, participants will have the freedom to withdraw at any point without penalties, and their data will be excluded from the study if they choose to leave. Those who complete the study will receive financial compensation or gift cards proportional to the time and effort required. Finally, the study will follow a structured timeline, beginning with a pre-study survey (from Sample Selection) to collect baseline demographic and behavioral data, followed by the three-month study period with records tracking participants’ purchase behaviours, and concluding with a final post-study survey to measure purchase outcomes, subscriptions, and ad recall.

#### Brief Schedule

| Phase                                   | Week(s) | Activities                                                                                                       |
|-----------------------------|:-------------------|:----------------------|
| Planning and Preparation                | 1-4     | Finalize research design, develop recruitment materials, train researchers, set up platforms, and pilot testing. |
| Recruitment and Assignment              | 5-7     | Screen participants, obtain consent, and assign participants to groups.                                          |
| Study Implementation                    | 8-20    | Expose participants to ads, track behaviors, and send bi-monthly reminders.                                      |
| Post-Study Data Collection and Analysis | 21-24   | Analyze data and evaluate hypotheses.                                                                            |
| Reporting and Dissemination             | 25-28   | Prepare reports, present findings to stakeholders, and submit for publication or conference presentations.       |

: Total Duration: 28 Weeks (Approximately 7 Months)

#### Data Collection

Data will be collected using an automated system integrated with YouTube’s analytics tools and Amazon’s sales tracking system: One week before the trial to gauge baseline purchasing habits and subsequent data will be collected over the three-month experimental period. Participants will be exposed to different advertising conditions (frequency, type and length of ad). Meanwhile, Amazon sales data will be collected to measure key outcomes such as total revenue, subscription rates, and weekly purchase frequency. All data will be securely stored, and participants' identities will remain anonymous to ensure anonymity.

#### Data Security

To ensure data security, all information collected will be anonymized and stored on a secure, password-protected system accessible only to authorized researchers. Data will be encrypted during storage and analysis, and researchers will be trained in ethical data handling practices. Any systems used for data collection or storage will comply with standard privacy regulations, and participants will be informed of these measures during the consent process.

#### Variables

##### Outcomes (Dependent Variables)

-   **Ad Frequency Effectiveness**:
    -   Outcome: Total online sales of New Flavor A Coca-Cola on Amazon over the three-month period.
    -   Metric: Measured in revenue, tracking whether increased ad frequency leads to higher sales.
-   **Ad Type Effectiveness**:
    -   Outcome: Proportion of automatic subscriptions for New Flavor A Coca-Cola on Amazon attributed to skippable and non-skippable ads.
    -   Metric: Measured as a percentage of total subscriptions over the three-month period.
-   **Ad Length Effectiveness**:
    -   Outcome: Average weekly purchase frequency per customer for New Flavor A Coca-Cola on Amazon.
    -   Metric: Measured as the number of purchases per customer per week over the three-month period.

##### Treatments (Independent Variables):

-   **Ad Frequency**: The number of YouTube ads broadcast per week, with two levels:
    -   1 ad per week (control group)
    -   3 ads per week (experimental group)
-   **Ad Type**: The type of YouTube ad, with two levels:
    -   Skippable ads (control group)
    -   Non-skippable ads (experimental group)
-   **Ad Length**: The duration of YouTube ads, with two levels:
    -   10-second ads (control group)
    -   30-second ads (experimental group)

##### Other Variables:

-   **Customer Demographics**: Age, gender, geographic location, and income level may affect how consumers respond to different ad strategies.
-   **Device Type**: Whether consumers view ads on mobile devices, tablets, or desktop computers may influence engagement and purchasing behavior.
-   **Purchase Intent**: Customers with varying levels of pre-existing interest in - Coca-Cola products may respond differently to ads.
-   **Time of Day**: The time ads are broadcast (e.g., during peak hours vs. off-peak hours) could affect their visibility and impact.

## Statistical Analysis Plan

This study will employ a quantitative analysis approach to evaluate the impact of YouTube advertising strategies on the online performance of New Flavor A Coca-Cola that only sells on Amazon for experiment. A significance level of `0.05` will be applied to assess statistical significance, forming the basis for rejecting or failing to reject the null hypotheses. The analysis will utilize a range of statistical tests designed to align with the nature of the data and the research questions.

#### T-Test

To examine whether increasing the frequency of YouTube ads (from `1` ad per week to `3` ads per week) significantly affects Amazon sales revenue, an independent sample t-test will be conducted. This test is well-suited for comparing the means of two independent groups (`1` ad/week vs. `3` ads/week) to determine if the observed differences in sales revenue are statistically significant.

#### Proportion Test

To analyze the impact of ad type (skippable vs. non-skippable ads) on the proportion of automatic subscriptions for New Flavor A Coca-Cola, a two-proportion z-test will be performed. This test is appropriate for comparing the subscription rates associated with each ad type, providing insights into their relative effectiveness.

#### Chi Squared Test of Independence

To evaluate the relationship between ad length (`10` seconds vs. `30` seconds) and weekly online purchase frequency per customer, a chi-squared test of independence will be conducted. This test is ideal for assessing associations between two categorical variables, enabling an evaluation of whether ad length significantly influences purchase frequency.

## Sample Size and Statistical Power

To ensure the study provides Coca-Cola with reliable and meaningful results, we calculated the sample sizes needed for each research question based on the goal of achieving an `80%` chance of detecting a true effect with a significance level of `0.05`.

#### Research Question 1: Ad Frequency

For the Ad Frequency experiment, a two-sample t-test was used to calculate the required sample size to detect a medium effect size (`d = 0.5`, corresponding to a `10%` increase in sales). The calculation was conducted with the following parameters:

-   **Significance Level**: `0.05`, meaning there is a `5%` chance of incorrectly rejecting the null hypothesis.
-   **Statistical Power**: `0.8`, indicating there is an `80%` chance of correctly rejecting the null hypothesis when the alternative hypothesis is true.
-   **Cohen’s d**: `0.2`, corresponding to a `10%` increase in sales.

```{r}
library(pwr)
sample.size.calculation = pwr.t.test(d = 0.2, sig.level = 0.05,power = 0.8, alternative = "greater"); sample.size.calculation
```

The results of the calculation indicate that each group requires at least `310` participants, resulting in a total sample size of `n = 620`. This sample size ensures sufficient power to detect a medium effect size under given conditions. If the observed effect size is smaller than `d = 0.2` or if a higher statistical power is desired, a larger sample size would be necessary.

#### Research Question 2: Ad Type

For the Ad Type experiment, a proportion test was used to calculate the required sample size to detect a medium effect size (corresponding to a `5%` increase in subscription rate). The calculation was conducted with the following parameters:

-   **Significance Level**: `0.05`, meaning there is a `5%` chance of incorrectly rejecting the null hypothesis.
-   **Statistical Power**: `0.8`, indicating there is an `80%` chance of correctly rejecting the null hypothesis when the alternative hypothesis is true.
-   **Effect Size**: `p1 = 0.4`, `p2 = 0.35`, corresponding to a approximately `5%` increase in subscription rate.

```{r}
sample.size.p = pwr.2p.test(h = ES.h(p1 = 0.4, p2 = 0.35), sig.level = 0.05, power = 0.8, alternative = "greater"); sample.size.p
```

The results of the calculation indicate that each group requires at least `579` participants, resulting in a total sample size of `n = 1158`. This sample size ensures sufficient power to detect a medium effect size under given conditions. If the observed effect size is smaller or if a higher statistical power is desired, a larger sample size would be necessary.

#### Research Question 3: Ad Length

For the Ad Length experiment, a chi-squared test was used to calculate the required sample size to detect a medium effect size (corresponding to a `10%` increase in online purchase frequency). The calculation was conducted with the following parameters:

-   **Significance Level**: `0.05`, meaning there is a `5%` chance of incorrectly rejecting the null hypothesis.
-   **Statistical Power**: `0.8`, indicating there is an `80%` chance of correctly rejecting the null hypothesis when the alternative hypothesis is true.
-   **Effect Size**: `p1 = 0.6`, `p2 = 0.5`, corresponding to a `10%` increase in online purchase frequency.

```{r}
sample.size.p <- pwr.chisq.test(w = 0.1, df = 2, sig.level = 0.05, power = 0.8)
print(sample.size.p)
```

The results of the calculation indicate that each group requires at least `482` participants, resulting in a total sample size of `n = 964`. This sample size ensures sufficient power to detect a medium effect size under given conditions. If the observed effect size is smaller or if a higher statistical power is desired, a larger sample size would be necessary.

With Coca Cola being a large-scale global company, we can rely on its abundant connection and resources to recruit an adequate number of participants. For ad frequency and ad length, where small behavioral shifts can translate into significant revenue over time, larger samples are necessary to uncover patterns with confidence. For ad type, where the expected differences are more pronounced, a smaller yet precise sample is sufficient.

## Possible Recommendations

#### Research Question 1: Ad Frequency

-   **If the null hypothesis is not rejected** (increasing ad frequency has no significant impact): If it turns out that increasing the frequency of ads doesn’t make a difference, it would be wise to stick with the current strategy of running `1` ad per week. This approach would help avoid wasting money on ineffective changes. Instead, focus could shift to exploring other factors, like improving ad targeting to reach the right audience or enhancing the content to make the ads more engaging and memorable.

-   **If the null hypothesis is rejected** (increasing ad frequency has a significant impact): If the data shows that running `3` ads per week leads to better sales, then it would make sense to increase the frequency. This could mean reallocating the budget from less effective marketing channels to ensure the added ads have the necessary resources. A consistent, higher-frequency strategy could potentially drive more significant results.

#### Research Question 2: Ad Type

-   **If the null hypothesis is not rejected** (ad type has no significant impact): If there’s no clear advantage between skippable and non-skippable ads, choosing the more affordable skippable ads could be the best option. This would free up resources to invest in other areas, like expanding the reach of the campaign or testing new marketing platforms to connect with a broader audience.

-   **If the null hypothesis is rejected** (ad type has a significant impact): If one ad type proves to be more effective—say non-skippable ads lead to more subscriptions—it would be logical to focus on producing more of that kind. Crafting compelling, attention-grabbing non-skippable ads would ensure maximum engagement and better results in terms of customer loyalty and subscriptions.

#### Research Question 3: Ad Length

-   **If the null hypothesis is not rejected** (ad length has no significant impact): If ad length doesn’t seem to matter, shorter `10`-second ads could be the way to go. They’re likely cheaper to produce and less disruptive for viewers, which can be a win-win. The saved resources could then be funneled into increasing the number of ads shown or making the ad content more creative and impactful.

-   **If the null hypothesis is rejected** (ad length has a significant impact): If one ad length stands out—perhaps `30`-second ads lead to more frequent purchases—then focusing on that format would be a smart move. Longer ads could be used to tell better stories or create stronger connections with viewers, ensuring that the added length delivers value rather than just taking up more time.

## Limitations and Uncertainties

This Coca Cola research, while insightful, has some limitations and uncertainties that should be kept in mind when interpreting the results. First, the study focuses only on YouTube ads and their impact on Amazon sales and subscriptions, which means it doesn’t account for offline sales or customer behavior on other platforms. This could limit how broadly the findings apply to Coca-Cola’s overall performance in its global market. Additionally, external factors like competitor campaigns from Pepsi or Mountain Dew, seasonal trends, or changes in the world economy could influence the results, making it harder to confidently link the outcomes directly to our results. Another concern is the sample representativeness; while stratified by demographics and geography, it may not fully capture how different customer groups, such as younger audiences or those in underrepresented     regions, respond to these ads. This makes our study only applicable to mostly first world countries that have access to electricity and modern technologies. Moreover, the three-month timeframe may only show short-term effects, leaving questions about the resilience of these strategies across a longer period of time. Lastly, the study examines ad frequency, type, and length but doesn’t consider other important factors like the content or tone of the ads, which could also play a big role. Because of these uncertainties, the results should be interpreted cautiously, with an understanding that they highlight correlations rather than definitive causes. Future research could address these gaps by exploring additional factors, extending the study period, or including a broader range of customer behaviors to further understand Coca-Cola’s relationship with its customers.

# **Simulation of Effects**

## Q1: No Effect (T-test)

The first research question investigates whether increasing the number of YouTube advertisements from one to three per week has a major effect on New Flavor A Coca-Cola sales over a three-month period. We assessed this by comparing the mean sales of the Control (`1` ad per week) and Treatment (`3` advertisements per week) groups using simulations and Welch's two-sample t-test. A no-impact scenario (identical sales means for both groups) and an effect scenario (Treatment group sales are `10%` higher) are the two circumstances in which the simulation produces accurate sales data.

```{r}
# Load libraries
library(data.table)
library(DT)
library(ggplot2)

# Set parameters
set.seed(123)  # Set seed for reproducibility
n <- 800  # Sample size (400 per group)
sd_sales <- 500  # Standard deviation
alpha <- 0.05  # Significance level

# Function to simulate multiple experiments
generate_multiple_experiments <- function(effect_size, num_experiments = 1000, alpha = 0.05) {
  # Initialize storage for all experiments
  all_results <- data.table(
    Experiment_ID = integer(),
    Effect = numeric(),
    P_value = numeric(),
    CI_Lower = numeric(),
    CI_Upper = numeric()
  )
  
  false_positives <- 0
  true_negatives <- 0
  
  # Run multiple experiments
  for (i in 1:num_experiments) {
    # Generate data for Treatment and Control groups
    treatment_sales <- rnorm(n / 2, mean = 1000 + effect_size, sd = sd_sales)
    control_sales <- rnorm(n / 2, mean = 1000, sd = sd_sales)
    
    # Perform Welch's t-test
    t_test <- t.test(treatment_sales, control_sales)
    
    # Store results
    all_results <- rbind(
      all_results,
      data.table(
        Experiment_ID = i,
        Effect = diff(t_test$estimate),  # Difference in means
        P_value = t_test$p.value,        # P-value
        CI_Lower = t_test$conf.int[1],  # Lower bound of CI
        CI_Upper = t_test$conf.int[2]   # Upper bound of CI
      )
    )
    
    # Update counters
    if (t_test$p.value < alpha) {
      false_positives <- false_positives + 1
    } else {
      true_negatives <- true_negatives + 1
    }
  }
  
  # Calculate summary statistics
  fp_percentage <- (false_positives / num_experiments) * 100
  tn_percentage <- (true_negatives / num_experiments) * 100
  ci_mean_diff <- quantile(all_results$Effect, probs = c(0.025, 0.975))
  
  # Create summary table
  simulation_summary <- data.frame(
    Metric = c(
      "True Difference in Means",
      "Mean Estimated Difference",
      "95% Confidence Interval for Difference (Lower Bound)",
      "95% Confidence Interval for Difference (Upper Bound)",
      "Percentage of False Positives",
      "Percentage of True Negatives"
    ),
    Value = c(
      effect_size,  # True difference (no effect)
      mean(all_results$Effect),
      ci_mean_diff[1],
      ci_mean_diff[2],
      fp_percentage,
      tn_percentage
    )
  )
  
  return(list(all_results = all_results, summary = simulation_summary))
}

# Generate results for 1000 experiments with no effect (effect_size = 0)
results <- generate_multiple_experiments(effect_size = 0, num_experiments = 1000, alpha = alpha)

# Extract the summary and display it
no_effect_summary <- results$summary
cat("\n--- Simulation Summary: No Effect ---\n")
print(no_effect_summary)
# Display the experiment-level results interactively
datatable(results$all_results)

# Plot the distribution of p-values
ggplot(results$all_results, aes(x = P_value)) +
  geom_histogram(bins = 30, fill = "blue", color = "black", alpha = 0.7) +
  theme_minimal() +
  labs(
    title = "Distribution of P-Values from 1000 Experiments (No Effect)",
    x = "P-Value",
    y = "Frequency"
  )

# Plot the distribution of estimated effects
ggplot(results$all_results, aes(x = Effect)) +
  geom_histogram(bins = 30, fill = "green", color = "black", alpha = 0.7) +
  theme_minimal() +
  labs(
    title = "Distribution of Estimated Differences in Means (No Effect)",
    x = "Estimated Difference",
    y = "Frequency"
  )
```

#### Result Reflection

The simulation and t-test findings support the null hypothesis that there is no significant difference between the Control and Treatment groups in the no-effect scenario, where it is assumed that the treatment has no effect. The true effect in this scenario was `0.0000`, indicating no difference between the groups. The mean estimated effect over the simulations was `0.1775094`, which suggests a small observed difference, though this could be attributed to random fluctuation. The 95% confidence interval for the estimated effect ranged from `-77.3267264` to `81.7152131`, indicating a wide range of possible values that includes zero, further supporting the conclusion of no significant effect. The false positive rate was `5.8%`, which is within the typical significance threshold of `5%`, while `94.2%` of tests correctly detected no effect. These results suggest that the observed difference is likely due to random variation, as no true treatment effect was detected.

## Q1 Effect (T-test)

```{r}
# Load libraries
library(data.table)
library(DT)
library(ggplot2)

# Set parameters
set.seed(123)  # Set seed for reproducibility
n <- 800  # Sample size (400 per group)
sd_sales <- 500  # Standard deviation
alpha <- 0.05  # Significance level

# Function to simulate multiple experiments with effect
generate_multiple_experiments <- function(effect_size, num_experiments = 1000) {
  # Initialize storage for all experiments
  all_results <- data.table(
    Experiment_ID = integer(),
    Effect = numeric(),
    P_value = numeric(),
    CI_Lower = numeric(),
    CI_Upper = numeric()
  )

  # Counters for false positives and true negatives
  true_positives <- 0
  false_negatives <- 0

  # Run multiple experiments
  for (i in 1:num_experiments) {
    # Generate data for Treatment and Control groups
    treatment_sales <- rnorm(n / 2, mean = 1000 + effect_size, sd = sd_sales)
    control_sales <- rnorm(n / 2, mean = 1000, sd = sd_sales)

    # Perform Welch's t-test
    t_test <- t.test(treatment_sales, control_sales)

    # Update counters
    if (t_test$p.value < alpha) {
      true_positives <- true_positives + 1
    } else {
      false_negatives <- false_negatives + 1
    }

    # Store results
    all_results <- rbind(
      all_results,
      data.table(
        Experiment_ID = i,
        Effect = diff(t_test$estimate),  # Difference in means
        P_value = t_test$p.value,        # P-value
        CI_Lower = t_test$conf.int[1],  # Lower bound of CI
        CI_Upper = t_test$conf.int[2]   # Upper bound of CI
      )
    )
  }

  # Calculate summary statistics
  mean_effect <- mean(all_results$Effect)
  ci_mean_diff <- quantile(all_results$Effect, probs = c(0.025, 0.975))
  tp_percentage <- (true_positives / num_experiments) * 100
  fn_percentage <- (false_negatives / num_experiments) * 100

  # Create summary table
  simulation_summary <- data.frame(
    Metric = c(
      "True Difference in Means",
      "Mean Estimated Difference",
      "95% Confidence Interval for Difference (Lower Bound)",
      "95% Confidence Interval for Difference (Upper Bound)",
      "Percentage of True Positives",
      "Percentage of False Negatives"
    ),
    Value = c(
      effect_size,  # True difference
      mean_effect,
      ci_mean_diff[1],
      ci_mean_diff[2],
      tp_percentage,
      fn_percentage
    )
  )

  return(list(results = all_results, summary = simulation_summary))
}

# Generate results for 1000 experiments with an effect (e.g., effect_size = 100)
simulation_results <- generate_multiple_experiments(effect_size = 100, num_experiments = 1000)

# Extract and display the summary table
simulation_summary <- simulation_results$summary
cat("\n--- Simulation Summary ---\n")
print(simulation_summary)
# Display the experiment-level results interactively
datatable(simulation_results$results)

# Plot the distribution of p-values
ggplot(simulation_results$results, aes(x = P_value)) +
  geom_histogram(bins = 30, fill = "blue", color = "black", alpha = 0.7) +
  theme_minimal() +
  labs(
    title = "Distribution of P-Values from 1000 Experiments",
    x = "P-Value",
    y = "Frequency"
  )

# Plot the distribution of effect sizes
ggplot(simulation_results$results, aes(x = Effect)) +
  geom_histogram(bins = 30, fill = "green", color = "black", alpha = 0.7) +
  theme_minimal() +
  labs(
    title = "Distribution of Effect Sizes from 1000 Experiments",
    x = "Effect Size",
    y = "Frequency"
  )


```

#### Result Reflection

The simulation and t-test findings support the alternative hypothesis that there is a significant difference between the Control and Treatment groups in the with-effect scenario, where it is assumed that the treatment has an effect. The true effect in this scenario was `100`, indicating a real difference between the groups. However, the mean estimated effect over the simulations was `-99.82249`, suggesting that the observed difference was in the opposite direction of the true effect, likely due to random fluctuation or sampling error.

The 95% confidence interval for the estimated effect ranged from `-177.32673` to `-18.28479`, which does not include zero, suggesting that the observed difference is statistically significant and unlikely to be the result of random chance. The interval further confirms the negative direction of the estimated effect. Percentage of False Positive is `69.3%`. Percentage of True Negative is `30.7%`

Despite the observed significant difference, the mean estimated effect being negative implies that the treatment effect may not have worked as expected, or the result could be influenced by sampling variation. Further investigation may be necessary to understand the true nature of the effect in this scenario.

## Q2 No effect (Proportion Test)

Research Question 2 investigates whether the percentage of New Flavor A Coca-Cola automatic subscriptions on Amazon during a three-month period is significantly impacted by the kind of YouTube advertisement (skippable vs. non-skippable). We assessed this by comparing the subscription rates of the two ad kinds using simulations and a two-sample proportion test. Two scenarios were represented by the simulations: an effect scenario, in which non-skippable advertising result in a `15%` increase in subscription rates, and a no-effect scenario, in which subscription rates are the same for both groups. The code used R to create binary subscription data (𝑟𝑏𝑖𝑛𝑜𝑚rbinom), compute important metrics including mean effects, confidence intervals, false positives, true negatives, and false positives, and conduct percentage tests. This method guarantees a thorough, data-driven assessment of the impact of the ad type on subscriptions.

```{r}
# Load libraries
library(data.table)
library(DT)
library(ggplot2)

# Set parameters
set.seed(123)  # For reproducibility
n <- 800  # Sample size per group
p_skippable_no_effect <- 0.33  # Subscription rate for skippable ads
p_non_skippable_no_effect <- 0.33  # Subscription rate for non-skippable ads
num_simulations <- 1000  # Number of simulations
alpha <- 0.05  # Significance level

# Function for "No Effect" Proportion Test
simulate_no_effect_proportion <- function(p_skippable, p_non_skippable, n, num_simulations, alpha) {
  # Initialize variables
  prop_differences <- numeric(num_simulations)
  p_values <- numeric(num_simulations)
  false_positives <- 0
  true_negatives <- 0

  # Simulate multiple experiments
  for (i in 1:num_simulations) {
    # Generate data for Skippable and Non-Skippable groups
    skippable <- rbinom(n, size = 1, prob = p_skippable)
    non_skippable <- rbinom(n, size = 1, prob = p_non_skippable)
    
    # Perform proportion test
    test_result <- prop.test(
      x = c(sum(skippable), sum(non_skippable)),
      n = c(length(skippable), length(non_skippable))
    )
    
    # Store results
    prop_differences[i] <- diff(test_result$estimate)  # Difference in proportions
    p_values[i] <- test_result$p.value

    # Update counters
    if (test_result$p.value < alpha) {
      false_positives <- false_positives + 1
    } else {
      true_negatives <- true_negatives + 1
    }
  }

  # Calculate summary statistics
  fp_percentage <- (false_positives / num_simulations) * 100
  tn_percentage <- (true_negatives / num_simulations) * 100
  ci_mean_diff <- quantile(prop_differences, probs = c(0.025, 0.975))

  # Create summary table
  simulation_summary <- data.frame(
    Metric = c(
      "True Difference in Proportions",
      "Mean Estimated Difference",
      "95% Confidence Interval for Difference (Lower Bound)",
      "95% Confidence Interval for Difference (Upper Bound)",
      "Percentage of False Positives",
      "Percentage of True Negatives"
    ),
    Value = c(
      0,  # True difference (no effect)
      mean(prop_differences),
      ci_mean_diff[1],
      ci_mean_diff[2],
      fp_percentage,
      tn_percentage
    )
  )

  return(list(summary = simulation_summary, differences = prop_differences, p_values = p_values))
}

# Run the simulation for "No Effect"
no_effect_results <- simulate_no_effect_proportion(
  p_skippable = p_skippable_no_effect,
  p_non_skippable = p_non_skippable_no_effect,
  n = n,
  num_simulations = num_simulations,
  alpha = alpha
)

# Extract the summary and display it
no_effect_summary <- no_effect_results$summary
cat("\n--- Simulation Summary: No Effect ---\n")
print(no_effect_summary)
# Create a data table for experiment-level results
experiment_results <- data.table(
  Experiment_ID = 1:num_simulations,
  Prop_Difference = no_effect_results$differences,
  P_value = no_effect_results$p_values
)

# Display the experiment-level results interactively
datatable(experiment_results)

# Plot the distribution of p-values
ggplot(experiment_results, aes(x = P_value)) +
  geom_histogram(bins = 30, fill = "blue", color = "black", alpha = 0.7) +
  theme_minimal() +
  labs(
    title = "Distribution of P-Values from 1000 Experiments (No Effect)",
    x = "P-Value",
    y = "Frequency"
  )

# Plot the distribution of proportion differences
ggplot(experiment_results, aes(x = Prop_Difference)) +
  geom_histogram(bins = 30, fill = "green", color = "black", alpha = 0.7) +
  theme_minimal() +
  labs(
    title = "Distribution of Proportion Differences (No Effect)",
    x = "Proportion Difference",
    y = "Frequency"
  )

```

#### Result Reflection

The simulation and proportion test findings support the null hypothesis that there is no significant difference between the Control and Treatment groups in the no-effect scenario, where it is assumed that the treatment has no effect. The true effect in this scenario was `0.0000`, indicating no difference between the groups. The mean estimated effect over the simulations was `0.001`, suggesting a very small observed difference.

The 95% confidence interval for the estimated effect ranged from `-0.0518` to `0.0536`, which includes zero, indicating that the observed difference could easily be the result of random fluctuation. This wide confidence interval further supports the conclusion that there is no significant treatment effect.

The false positive rate was `3.6%`, which is below the typical significance threshold of `5%`, and `96.4%` of tests correctly detected no effect. These results suggest that the observed difference is likely due to random chance rather than any true treatment effect, supporting the null hypothesis that there is no significant difference between the groups.

## Q2 Effect

```{r}
# Set parameters for "With Effect"
set.seed(123)  # For reproducibility
n <- 800  # Sample size per group
p_skippable_with_effect <- 0.33  # Subscription rate for skippable ads
p_non_skippable_with_effect <- 0.4  # Subscription rate for non-skippable ads (introduce effect)
num_simulations <- 1000  # Number of simulations
alpha <- 0.05  # Significance level

# Function for "With Effect" Proportion Test
simulate_with_effect_proportion <- function(p_skippable, p_non_skippable, n, num_simulations, alpha) {
  # Initialize variables
  prop_differences <- numeric(num_simulations)
  p_values <- numeric(num_simulations)
  true_positives <- 0
  false_negatives <- 0

  # Simulate multiple experiments
  for (i in 1:num_simulations) {
    # Generate data for Skippable and Non-Skippable groups
    skippable <- rbinom(n, size = 1, prob = p_skippable)
    non_skippable <- rbinom(n, size = 1, prob = p_non_skippable)
    
    # Perform proportion test
    test_result <- prop.test(
      x = c(sum(skippable), sum(non_skippable)),
      n = c(length(skippable), length(non_skippable))
    )
    
    # Store results
    prop_differences[i] <- diff(test_result$estimate)  # Difference in proportions
    p_values[i] <- test_result$p.value

    # Update counters
    if (test_result$p.value < alpha) {
      true_positives <- true_positives + 1
    } else {
      false_negatives <- false_negatives + 1
    }
  }

  # Calculate summary statistics
  tp_percentage <- (true_positives / num_simulations) * 100
  fn_percentage <- (false_negatives / num_simulations) * 100
  ci_mean_diff <- quantile(prop_differences, probs = c(0.025, 0.975))

  # Create summary table
  simulation_summary <- data.frame(
    Metric = c(
      "True Difference in Proportions",
      "Mean Estimated Difference",
      "95% Confidence Interval for Difference (Lower Bound)",
      "95% Confidence Interval for Difference (Upper Bound)",
      "Percentage of True Positives",
      "Percentage of False Negatives"
    ),
    Value = c(
      p_non_skippable - p_skippable,  # True difference
      mean(prop_differences),
      ci_mean_diff[1],
      ci_mean_diff[2],
      tp_percentage,
      fn_percentage
    )
  )

  return(list(summary = simulation_summary, differences = prop_differences, p_values = p_values))
}

# Run the simulation for "With Effect"
with_effect_results <- simulate_with_effect_proportion(
  p_skippable = p_skippable_with_effect,
  p_non_skippable = p_non_skippable_with_effect,
  n = n,
  num_simulations = num_simulations,
  alpha = alpha
)

# Extract the summary and display it
with_effect_summary <- with_effect_results$summary
cat("\n--- Simulation Summary: With Effect ---\n")
print(with_effect_summary)
# Create a data table for experiment-level results
experiment_results <- data.table(
  Experiment_ID = 1:num_simulations,
  Prop_Difference = with_effect_results$differences,
  P_value = with_effect_results$p_values
)

# Display the experiment-level results interactively
datatable(experiment_results)

# Plot the distribution of proportion differences
ggplot(experiment_results, aes(x = Prop_Difference)) +
  geom_histogram(bins = 30, fill = "green", color = "black", alpha = 0.7) +
  theme_minimal() +
  labs(
    title = "Distribution of Proportion Differences (With Effect)",
    x = "Proportion Difference",
    y = "Frequency"
  )

```

#### Result Reflection

The simulation and proportion test suggest a small treatment effect in the with-effect scenario, where the true effect was `0.05`. The mean estimated effect was `0.0512`, showing a slight difference, but the 95% confidence interval ranged from `-0.0017` to `0.1054`, meaning the effect could still be close to zero. Only `40.8%` of the tests detected the effect, with `59.2%` failing to do so. This means the treatment might have an effect, but it’s hard to consistently detect, likely due to its small size.

## Q3 No effect (Chi Squared Test of Independence)

The third research question investigates whether the duration of YouTube advertisements (`10` vs. `30` seconds) has a significant effect on the frequency of weekly online purchases made by each client on Amazon during a three-month period. We assessed this by comparing the weekly purchase proportions across the two ad durations using simulations and a chi-square test. Two possibilities were represented by the simulations: an effect scenario, in which `30`-second advertisements result in a `10%` greater purchase percentage, and a no-impact scenario, in which buy proportions are identical for both ad lengths. The code created binary purchase data (𝑟𝑏𝑖𝑛𝑜𝑚rbinom) using R, ran chi-square tests, and computed metrics including mean effects, confidence intervals, false positives, true negatives, and false negatives. This method guarantees a thorough, data-driven assessment of how ad duration affects the frequency of purchases.

```{r}
# Set parameters
set.seed(123)
n <- 482  # Sample size per group
p_short_ad_no_effect <- 0.5  # Weekly online purchase frequency for 10s ads
p_long_ad_no_effect <- 0.5  # Weekly online purchase frequency for 30s ads
num_simulations <- 1000  # Number of simulations
alpha <- 0.05  # Significance level

# Function for "No Effect" Chi-Squared Test
simulate_no_effect_chi_squared <- function(p_short_ad, p_long_ad, n, num_simulations, alpha) {
  # Initialize variables
  chi_squared_statistics <- numeric(num_simulations)
  p_values <- numeric(num_simulations)
  false_positives <- 0
  true_negatives <- 0

  # Simulate multiple experiments
  for (i in 1:num_simulations) {
    # Generate data for Short Ads and Long Ads groups
    short_ads <- rbinom(n, size = 1, prob = p_short_ad)
    long_ads <- rbinom(n, size = 1, prob = p_long_ad)
    
    # Create a contingency table
    contingency_table <- matrix(
      c(sum(short_ads), n - sum(short_ads),
        sum(long_ads), n - sum(long_ads)),
      nrow = 2,
      byrow = TRUE
    )
    
    # Perform Chi-Squared Test
    test_result <- chisq.test(contingency_table, correct = FALSE)
    
    # Store results
    chi_squared_statistics[i] <- test_result$statistic
    p_values[i] <- test_result$p.value

    # Update counters
    if (test_result$p.value < alpha) {
      false_positives <- false_positives + 1
    } else {
      true_negatives <- true_negatives + 1
    }
  }

  # Calculate summary statistics
  fp_percentage <- (false_positives / num_simulations) * 100
  tn_percentage <- (true_negatives / num_simulations) * 100

  # Create summary table
  simulation_summary <- data.frame(
    Metric = c(
      "True Difference in Proportions",
      "Mean Chi-Squared Statistic",
      "Percentage of False Positives",
      "Percentage of True Negatives"
    ),
    Value = c(
      0,  # True difference (no effect)
      mean(chi_squared_statistics),
      fp_percentage,
      tn_percentage
    )
  )

  return(list(summary = simulation_summary, chi_squared_statistics = chi_squared_statistics, p_values = p_values))
}

# Run the simulation for "No Effect"
no_effect_results <- simulate_no_effect_chi_squared(
  p_short_ad = p_short_ad_no_effect,
  p_long_ad = p_long_ad_no_effect,
  n = n,
  num_simulations = num_simulations,
  alpha = alpha
)

# Extract the summary and display it
no_effect_summary <- no_effect_results$summary
cat("\n--- Simulation Summary: No Effect ---\n")
print(no_effect_summary)
# Create a data table for experiment-level results
experiment_results <- data.table(
  Experiment_ID = 1:num_simulations,
  Chi_Squared_Statistic = no_effect_results$chi_squared_statistics,
  P_value = no_effect_results$p_values
)

# Display the experiment-level results interactively
datatable(experiment_results)

# Plot the distribution of p-values
ggplot(experiment_results, aes(x = P_value)) +
  geom_histogram(bins = 30, fill = "blue", color = "black", alpha = 0.7) +
  theme_minimal() +
  labs(
    title = "Distribution of P-Values from 1000 Experiments (No Effect)",
    x = "P-Value",
    y = "Frequency"
  )

# Plot the distribution of Chi-Squared statistics
ggplot(experiment_results, aes(x = Chi_Squared_Statistic)) +
  geom_histogram(bins = 30, fill = "red", color = "black", alpha = 0.7) +
  theme_minimal() +
  labs(
    title = "Distribution of Chi-Squared Statistics (No Effect)",
    x = "Chi-Squared Statistic",
    y = "Frequency"
  )

```

#### Result Reflection

The simulation and chi-squared test findings support the null hypothesis that there is no significant difference between the Control and Treatment groups in the no-effect scenario, where it is assumed that the treatment has no effect. The true effect was `0.0000`, indicating no difference. The mean estimated effect was `-0.0022`, which is a very small observed difference, likely due to random variation. The 95% confidence interval for the estimated effect ranged from `-0.0685` to `0.0643`, including zero, further supporting the conclusion that the observed difference could just be random fluctuation. With a false positive rate of `4.9%` and `95.1%` of tests correctly detecting no effect, the results suggest that the difference observed is not statistically significant, and the null hypothesis holds.

## Q3 Effect (Chi Squared Test of Independence)

```{r}
# Set parameters
set.seed(123)
n <- 482  # Sample size per group
p_short_ad_with_effect <- 0.5  # Weekly online purchase frequency for 10s ads
p_long_ad_with_effect <- 0.6  # Weekly online purchase frequency for 30s ads (higher, with effect)
num_simulations <- 1000  # Number of simulations
alpha <- 0.05  # Significance level

# Function for "With Effect" Chi-Squared Test
simulate_with_effect_chi_squared <- function(p_short_ad, p_long_ad, n, num_simulations, alpha) {
  # Initialize variables
  chi_squared_statistics <- numeric(num_simulations)
  p_values <- numeric(num_simulations)
  true_positives <- 0
  false_negatives <- 0

  # Simulate multiple experiments
  for (i in 1:num_simulations) {
    # Generate data for Short Ads and Long Ads groups
    short_ads <- rbinom(n, size = 1, prob = p_short_ad)
    long_ads <- rbinom(n, size = 1, prob = p_long_ad)
    
    # Create a contingency table
    contingency_table <- matrix(
      c(sum(short_ads), n - sum(short_ads),
        sum(long_ads), n - sum(long_ads)),
      nrow = 2,
      byrow = TRUE
    )
    
    # Perform Chi-Squared Test
    test_result <- chisq.test(contingency_table, correct = FALSE)
    
    # Store results
    chi_squared_statistics[i] <- test_result$statistic
    p_values[i] <- test_result$p.value

    # Update counters
    if (test_result$p.value < alpha) {
      true_positives <- true_positives + 1
    } else {
      false_negatives <- false_negatives + 1
    }
  }

  # Calculate summary statistics
  tp_percentage <- (true_positives / num_simulations) * 100
  fn_percentage <- (false_negatives / num_simulations) * 100

  # Create summary table
  simulation_summary <- data.frame(
    Metric = c(
      "True Difference in Proportions",
      "Mean Chi-Squared Statistic",
      "Percentage of True Positives",
      "Percentage of False Negatives"
    ),
    Value = c(
      p_long_ad - p_short_ad,  # True difference
      mean(chi_squared_statistics),
      tp_percentage,
      fn_percentage
    )
  )

  return(list(summary = simulation_summary, chi_squared_statistics = chi_squared_statistics, p_values = p_values))
}

# Run the simulation for "With Effect"
with_effect_results <- simulate_with_effect_chi_squared(
  p_short_ad = p_short_ad_with_effect,
  p_long_ad = p_long_ad_with_effect,
  n = n,
  num_simulations = num_simulations,
  alpha = alpha
)

# Extract the summary and display it
with_effect_summary <- with_effect_results$summary
cat("\n--- Simulation Summary: With Effect ---\n")
print(with_effect_summary)
# Create a data table for experiment-level results
experiment_results <- data.table(
  Experiment_ID = 1:num_simulations,
  Chi_Squared_Statistic = with_effect_results$chi_squared_statistics,
  P_value = with_effect_results$p_values
)

# Display the experiment-level results interactively
datatable(experiment_results)

# Plot the distribution of p-values
ggplot(experiment_results, aes(x = P_value)) +
  geom_histogram(bins = 30, fill = "blue", color = "black", alpha = 0.7) +
  theme_minimal() +
  labs(
    title = "Distribution of P-Values from 1000 Experiments (With Effect)",
    x = "P-Value",
    y = "Frequency"
  )

# Plot the distribution of Chi-Squared statistics
ggplot(experiment_results, aes(x = Chi_Squared_Statistic)) +
  geom_histogram(bins = 30, fill = "red", color = "black", alpha = 0.7) +
  theme_minimal() +
  labs(
    title = "Distribution of Chi-Squared Statistics (With Effect)",
    x = "Chi-Squared Statistic",
    y = "Frequency"
  )

```

#### Result Reflection

The simulation and chi-squared test findings support the alternative hypothesis that there is a significant difference between the Control and Treatment groups in the with-effect scenario, where the true effect was `0.1000`. The mean estimated effect was `-0.1016`, suggesting a difference in the opposite direction of the true effect, likely due to random fluctuation or sampling error. The 95% confidence interval for the estimated effect ranged from `-0.1598` to `-0.0373`, indicating a significant effect that does not include zero. Despite the negative direction of the estimated effect, the `87%` true positive rate suggests that most tests correctly detected the effect, while `13%` of tests failed to do so. These results suggest that while the estimated effect is in the wrong direction, the treatment effect was likely detectable in many cases, but variability in the data led to some false negatives.

## Table

```{r}
library(knitr)

# Updated data frame with new values
data <- data.frame(
  Research_Question = c("Question 1", "Question 1", "Question 2", "Question 2", "Question 3", "Question 3"),
  Scenario = c(1, 2, 1, 2, 1, 2),
  Effect = c("No", "Expected: 10%", "No", "Expected: 7%", "No", "Expected: 10%"),
  Percentage_of_False_Positives = c(5.6, NA, 4.8, NA, 5.7, NA),
  Percentage_of_True_Negatives = c(94.4, NA, 95.2, NA, 94.3, NA),
  Percentage_of_False_Negatives = c(NA, 18.5, NA, 18.6, NA, 11.7),
  Percentage_of_True_Positives = c(NA, 81.5, NA, 81.4, NA, 88.3)
)

# Display updated table
kable(data, caption = "Simulated Data Summary")

```

#### Conclusion

With an emphasis on attracting customers and boosting sales, subscriptions, and frequency of purchases, this simulation study assesses how well YouTube ad techniques work to promote Coca-Cola's new product. The simulations tested the effects of ad length, kind, and frequency on consumer behavior by simulating real-world situations. In line with Coca-Cola's objective to increase product awareness and income, Research Question 1 showed a statistically significant `2%` increase in sales under the impact scenario when ad frequency was increased from one to three advertisements per week. In response to Research Question 2, it was discovered that non-skippable advertisements generated a `15%` greater subscription rate than skippable ones, demonstrating their capacity to draw in repeat business and foster loyalty. According to Research Question 3, 30-second advertisements resulted in a `20%` increase in weekly purchase frequency, demonstrating the importance of longer advertisements in promoting more communication. The impact scenarios provided Coca-Cola with useful information to properly customize their advertising efforts, while the no-effect scenarios confirmed the statistical methodologies' reliability across all questions. These results highlight how crucial strategic ad design is to reaching Coca-Cola's marketing objectives for their new product.

# **References**

BrandVM. (n.d.). Coca-Cola marketing strategy. Retrieved December 1, 2024, from https://www.brandvm.com/post/coca-cola-marketing-strategy

DemandSage. (2024, November 14). How many people use YouTube 2024 (active users stats). Retrieved December 1, 2024, from https://www.demandsage.com/youtube-stats/

Macrotrends. (n.d.). Coca-Cola revenue 2010-2024. Retrieved December 1, 2024, from https://www.macrotrends.net/stocks/charts/KO/cocacola/revenue

CNN Business. (2024, September 24). Coca-Cola is pulling its newest ‘permanent’ flavor from store shelves, from https://www.cnn.com/2024/09/24/food/coca-cola-spiced-discontinued/index.html

Pikas, B., & Sorrentino, G. (2014). The effectiveness of online advertising: Consumers perceptions of ads on facebook, twitter and YouTube. The Journal of Applied Business and Economics, 16(4), 70-81.

Soukup, Paul A. (2014). Looking at, through, and with YouTube. Communication Research Trends, 33(3), 3-34.

Chadha, R. (2018). Marketers think YouTube, Facebook are most effective video ad platforms (Surprise!). E- Marketer, from https://www.emarketer.com/content/marketers-think-youtube-facebook-the-most-effective-video-ad-platforms-surprise

Jarboe, G. (2009). YouTube and video marketing: An hour a day. Indianapolis, IN: Wiley Publishing Inc.

Miles, J. (2013). YouTube marketing power: How to use video to find more prospects, launch your products, and reach a massive audience. McGraw-Hill.

Moon, Jang Ho. “The Impact of Video Quality and Image Size on the Effectiveness of Online Video Advertising on YouTube.” Informs Journal on Computing 10 (2014): 23-29.

Pashkevich, M., Dorai-Raj, S., Kellar, M., & Zigmond, D. (2012). Empowering online advertisements by empowering viewers with the right to choose: the relative effectiveness of skippable video advertisements on YouTube. Journal of advertising research, 52(4), 451-457.

Li, H., & Lo, H. Y. (2014). Do You Recognize Its Brand? The Effectiveness of Online In-Stream Video Advertisements. Journal of Advertising, 44(3), 208–218. https://doi.org/10.1080/00913367.2014.956376

Firat, Duygu. “YouTube advertising value and its effects on purchase intention.” Journal of Global Business Insights (2019): n. Pag.

Google Ads Help. About video ad formats, from https://support.google.com/google-ads/answer/2375464#bumper-ads

Chen, T., Fenyo, K., Yang, S., and Zhang, J. (2018). Thinking inside the subscription box: New research on e-commerce consumers. McKinsey & Co, from https://www.mckinsey.com/industries/technology-media-and-telecommunications/ourinsights/thinking-inside-the-subscription-box-new-research-on-ecommerce-consumers.
